{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d6296d-9187-4737-ab9b-b73bc0d521bc",
   "metadata": {},
   "source": [
    "# **Final Presentation**\n",
    "\n",
    "\n",
    "\n",
    "In this notebook team Power_Factor will describe its developed package: the different functionalities, the completed assignments that led to the developement of the package as well as some code demonstrations and collaboration discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b52833-9e5e-40c8-a268-43a2bc0c35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_array\n",
    "from IPython.display import display\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from power_grid_model.utils import json_deserialize, json_serialize\n",
    "from power_grid_model.validation import ValidationException, assert_valid_batch_data, assert_valid_input_data\n",
    "from power_grid_model import (\n",
    "    CalculationMethod,\n",
    "    CalculationType,\n",
    "    ComponentType,\n",
    "    DatasetType,\n",
    "    PowerGridModel,\n",
    "    initialize_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8859b97",
   "metadata": {},
   "source": [
    "# **Assignment 1 -graph processing**\n",
    "\n",
    "In assignment 1 the task is to build a graph processing class. For a given undirected graph as input, there are two functionalities to implement:\n",
    "- Find downstream vertices - given a specific edge from the graph, find the downstream vertices of the edge, including the downstream vertex of the edge itself\n",
    "- Find alternative edges - given a specific enabled edge from the graph, returns a list that indicates which currently disabled edges can be enabled so that the graph is again fully connected and acyclic\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742795ef",
   "metadata": {},
   "source": [
    "# **Check input validity**\n",
    "\n",
    "Before the either of the two functionalities are used, the input data must be checked for validity. There are 7 criteria that are evaluated:\n",
    "1. The vertex (node) and edge ids should be unique\n",
    "2. The number of edges (or connections between two separate vertices) should have the same as the number of edge ids\n",
    "3. The vertices connected by the specified edges should be valid vertex ids\n",
    "4. The number of enabled/disabled edges should be the same as the number of edge ids\n",
    "5. The id of the source vertex should be a valid vertex id\n",
    "6. The graph should be fully connected\n",
    "7. The graph should not contain cycles\n",
    "\n",
    "Furthermore, Find alternative edges functionality it is important to check if the edge to be disabled has a valid id and whether it is already disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787f2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDNotFoundError(Exception):\n",
    "    \"Raised when a source or edge id is not found/valid\"\n",
    "\n",
    "\n",
    "class InputLengthDoesNotMatchError(Exception):\n",
    "    \"Raised when number of enabled and disabled edges does not match number of total edges or number of vertex pairs does not match number of edges\"\n",
    "\n",
    "\n",
    "class IDNotUniqueError(Exception):\n",
    "    \"Raised when vertex or edge ids are not unique\"\n",
    "\n",
    "\n",
    "class GraphNotFullyConnectedError(Exception):\n",
    "    \"Raised when graph contains more than 1 component\"\n",
    "\n",
    "\n",
    "class GraphCycleError(Exception):\n",
    "    \"Raised when graph contains a cycle\"\n",
    "\n",
    "\n",
    "class EdgeAlreadyDisabledError(Exception):\n",
    "    \"Edge is already disabled\"\n",
    "\n",
    "\n",
    "def check_unique(vertex_ids, edge_ids): #checks vertex ids or edge ids are unique\n",
    "    ver = list(set(vertex_ids)) #a set is used because sets contain only unique values\n",
    "    edge = list(set(edge_ids))\n",
    "    if len(ver) != len(vertex_ids) or len(edge) != len(edge_ids):\n",
    "        raise IDNotUniqueError(\"Vertex or edge ids are not unique\")\n",
    "\n",
    "\n",
    "def check_length_pairs(edge_vertex_id_pairs, edge_ids): #checks if number of vertex pairs matches the number of edges\n",
    "    if len(edge_vertex_id_pairs) != len(edge_ids):\n",
    "        raise InputLengthDoesNotMatchError(\"Number of vertex pairs does not match number of edges\")\n",
    "\n",
    "\n",
    "def check_found_pairs(edge_vertex_id_pairs, vertex_ids): #checks if all vertex pairs contain valid vertex ids\n",
    "    if all(all(elem in vertex_ids for elem in t) for t in edge_vertex_id_pairs) == False:\n",
    "        raise IDNotFoundError(\"Vertex id not found in edge array\")\n",
    "    \n",
    "\n",
    "def check_length_enabled(edge_enabled, edge_ids): #checks if the number of enabled/disabled edges is the same as the number of edge ids\n",
    "    if len(edge_enabled) != len(edge_ids):\n",
    "        raise InputLengthDoesNotMatchError(\"Number of enabled and disabled edges does not match number of total edges\")\n",
    "\n",
    "\n",
    "def check_found_source(source_vertex_id, vertex_ids): #checks if the source vertex id is valid\n",
    "    if source_vertex_id not in vertex_ids:\n",
    "        raise IDNotFoundError(\"Source vertex id not found\")\n",
    "\n",
    "\n",
    "def check_connect(vertex_ids, edge_enabled, edge_vertex_id_pairs): #checks if graph is fully connected\n",
    "    size = len(vertex_ids)\n",
    "    sparseMatrix = [[0 for i in range(size)] for j in range(size)]\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if ((vertex_ids[i], vertex_ids[j]) in edge_vertex_id_pairs) and sparseMatrix[i][j] == 0:\n",
    "                if edge_enabled[edge_vertex_id_pairs.index((vertex_ids[i], vertex_ids[j]))]:\n",
    "                    sparseMatrix[i][j] = vertex_ids[j]\n",
    "                    sparseMatrix[j][i] = vertex_ids[i]\n",
    "            elif ((vertex_ids[j], vertex_ids[i]) in edge_vertex_id_pairs) and sparseMatrix[i][j] == 0:\n",
    "                if edge_enabled[edge_vertex_id_pairs.index((vertex_ids[j], vertex_ids[i]))]:\n",
    "                    sparseMatrix[i][j] = vertex_ids[j]\n",
    "                    sparseMatrix[j][i] = vertex_ids[i]\n",
    "    graph = csr_array(sparseMatrix)\n",
    "    components = connected_components(graph)\n",
    "    if components[0] > 1:\n",
    "        raise GraphNotFullyConnectedError(\"Graph contains more than 1 component\")\n",
    "\n",
    "\n",
    "def check_cycle(edge_enabled, edge_vertex_id_pairs): #checks if graph contains cycles\n",
    "    G = nx.Graph()\n",
    "    for (u, v), enabled in zip(edge_vertex_id_pairs, edge_enabled):\n",
    "        if enabled:\n",
    "            G.add_edge(u, v)\n",
    "\n",
    "    has_cycle = nx.is_forest(G)  # A forest is a graph with no undirected cycles\n",
    "    if has_cycle == False:\n",
    "        raise GraphCycleError(\"Graph contains a cycle\")\n",
    "\n",
    "\n",
    "def check_found_edges(disabled_edge_id, all_edges): #checks if the edge to be disabled has a valid edge id\n",
    "    if disabled_edge_id not in all_edges:\n",
    "        raise IDNotFoundError(\"Disabled edge id not found in edge array\")\n",
    "    \n",
    "\n",
    "def check_disabled(disabled_edge_id, edge_ids, edge_enabled): #checks if the edge to be disabled is already disabled\n",
    "    if edge_enabled[edge_ids.index(disabled_edge_id)] == False:\n",
    "        raise EdgeAlreadyDisabledError(\"Edge is already disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb58586",
   "metadata": {},
   "source": [
    "With all of the necessary needed external functions declared, the graph processing class can now also be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42465a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphProcessor(nx.Graph):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vertex_ids: List[int],\n",
    "        edge_ids: List[int],\n",
    "        edge_vertex_id_pairs: List[Tuple[int, int]],\n",
    "        edge_enabled: List[bool],\n",
    "        source_vertex_id: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        check_unique(vertex_ids, edge_ids)\n",
    "        check_length_pairs(edge_vertex_id_pairs, edge_ids)\n",
    "        check_found_pairs(edge_vertex_id_pairs, vertex_ids)\n",
    "        check_length_enabled(edge_enabled, edge_ids)\n",
    "        check_found_source(source_vertex_id, vertex_ids)\n",
    "        check_connect(vertex_ids, edge_enabled, edge_vertex_id_pairs)\n",
    "        check_cycle(edge_enabled, edge_vertex_id_pairs)\n",
    "\n",
    "        self.source_vertex_id = source_vertex_id\n",
    "        self.vertex_ids = vertex_ids\n",
    "        self.edge_enabled = edge_enabled\n",
    "        self.edge_ids = edge_ids\n",
    "        self.edge_vertex_id_pairs = edge_vertex_id_pairs\n",
    "        self.add_nodes_from(vertex_ids)\n",
    "        for i, (u, v) in enumerate(edge_vertex_id_pairs):\n",
    "            self.add_edge(u, v, id=edge_ids[i], enabled=edge_enabled[i])\n",
    "\n",
    "        self.enabled_subgraph = nx.Graph()\n",
    "        for (u, v), enabled in zip(edge_vertex_id_pairs, edge_enabled):\n",
    "            if enabled:\n",
    "                self.enabled_subgraph.add_edge(u, v)\n",
    "        # DFS tree & parent map from source\n",
    "        self.dfs_tree = nx.dfs_tree(self.enabled_subgraph, self.source_vertex_id)\n",
    "        self.parent_map = {child: parent for parent, child in nx.dfs_edges(self.dfs_tree, source=self.source_vertex_id)}\n",
    "\n",
    "    def find_downstream_vertices(self, edge_id: int) -> List[int]:\n",
    "        if edge_id not in self.edge_ids:\n",
    "            raise IDNotFoundError(\"Edge ID not found.\")\n",
    "\n",
    "        edge_index = self.edge_ids.index(edge_id)\n",
    "        if not self.edge_enabled[edge_index]:\n",
    "            return []\n",
    "\n",
    "        u, v = self.edge_vertex_id_pairs[edge_index]\n",
    "\n",
    "        # Ensure both u and v are reachable\n",
    "        if u not in self.dfs_tree or v not in self.dfs_tree:\n",
    "            return []\n",
    "\n",
    "        # Determine downstream vertex (child in DFS tree)\n",
    "        if self.parent_map.get(v) == u:\n",
    "            downstream_root = v\n",
    "        elif self.parent_map.get(u) == v:\n",
    "            downstream_root = u\n",
    "        else:\n",
    "            # If neither is parent of the other, one of them is ancestor; pick the child\n",
    "            # or fallback to whichever is deeper\n",
    "            depth = nx.single_source_shortest_path_length(self.dfs_tree, self.source_vertex_id)\n",
    "            downstream_root = v if depth.get(v, 0) > depth.get(u, 0) else u\n",
    "\n",
    "        descendants = list(nx.descendants(self.dfs_tree, downstream_root))\n",
    "        return [downstream_root] + descendants\n",
    "\n",
    "    def find_alternative_edges(self, disabled_edge_id: int) -> List[int]:\n",
    "        ans = []\n",
    "        check_found_edges(disabled_edge_id, self.edge_ids)\n",
    "        check_disabled(disabled_edge_id, self.edge_ids, self.edge_enabled)\n",
    "        H = nx.Graph()\n",
    "        for i, (u, v) in enumerate(self.edge_vertex_id_pairs):\n",
    "            if self.edge_enabled[i] == True and self.edge_ids[i] != disabled_edge_id:\n",
    "                H.add_edge(u, v)\n",
    "        for i, (u, v) in enumerate(self.edge_vertex_id_pairs):\n",
    "            if self.edge_enabled[i] == False and self.edge_ids[i] != disabled_edge_id:\n",
    "                H.add_edge(u, v)\n",
    "                if nx.number_connected_components(H) == 1 and nx.is_forest(H):\n",
    "                    ans.append(self.edge_ids[i])\n",
    "                H.remove_edge(u, v)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03aaf57",
   "metadata": {},
   "source": [
    "With the class implemented its functionalities can now be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55e5ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of alternative edges when disabling edge 3 is: [7, 8]\n"
     ]
    }
   ],
   "source": [
    "vertex_ids1 = [0, 2, 4, 6, 10]\n",
    "edge_ids1 = [1, 3, 5, 7, 9, 8]\n",
    "edge_vertex_id_pairs1 = [(0, 2), (0, 4), (0, 6), (2, 4), (2, 10), (4, 6)]\n",
    "edge_enabled1 = [True, True, True, False, True, False]\n",
    "source_vertex_id1 = 0\n",
    "\n",
    "\"\"\"\n",
    "vertex_0 (source) --edge_1(enabled)-- vertex_2 --edge_9(enabled)-- vertex_10\n",
    "|                               |\n",
    "|                           edge_7(disabled)\n",
    "|                               |\n",
    "-----------edge_3(enabled)-- vertex_4\n",
    "|                               |\n",
    "|                           edge_8(disabled)\n",
    "|                               |\n",
    "-----------edge_5(enabled)-- vertex_6\n",
    "\"\"\"\n",
    "\n",
    "test_graph1=GraphProcessor(vertex_ids1, edge_ids1, edge_vertex_id_pairs1, edge_enabled1, source_vertex_id1)\n",
    "edge_to_disable=3\n",
    "print(f\"The list of alternative edges when disabling edge {edge_to_disable} is: {test_graph1.find_alternative_edges(edge_to_disable)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285c1151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of downstream vertices for edge 3 is [4, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "vertex_ids2 = [0, 2, 4, 6, 8, 10, 12]\n",
    "edge_ids2 = [1, 3, 5, 7, 9, 11]\n",
    "edge_vertex_id_pairs2 = [(0, 2), (2, 4), (2, 6), (4, 8), (8, 10), (6, 12)]\n",
    "edge_enabled2 = [True, True, True, True, True, True]\n",
    "source_vertex_id2 = 0\n",
    "\n",
    "\"\"\"\n",
    "    vertex_0 (source) --edge_1-- vertex_2 --edge_3-- vertex_4--edge 7--vertex 8 --edge 9--vertex 10\n",
    "                                    |\n",
    "                                  edge 5\n",
    "                                    |\n",
    "                                 vertex 6  --edge 11 --vertex 12\n",
    "\"\"\"\n",
    "\n",
    "test_graph2=GraphProcessor(vertex_ids2, edge_ids2, edge_vertex_id_pairs2, edge_enabled2, source_vertex_id2)\n",
    "edge_down=3\n",
    "print(f\"The list of downstream vertices for edge {edge_down} is {test_graph2.find_downstream_vertices(edge_down)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7abf7c",
   "metadata": {},
   "source": [
    "# **Assignment 2 - power grid model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccbb04d",
   "metadata": {},
   "source": [
    "# **Assignment 3 - developing a power system simulation package**\n",
    "\n",
    "Now that graph processing and power grid model have been implemented, they can be combined to form a functional user package to simulate power systems. The package has 4 functionalities:\n",
    "\n",
    "1. Input data validity check\n",
    "2. EV penetration level\n",
    "3. Optimal tap position\n",
    "4. N-1 calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c78b18d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lv_busbar': 1,\n",
      " 'lv_feeders': [1204, 1304, 1404, 1504, 1604, 1704, 1804, 1904],\n",
      " 'mv_source_node': 0,\n",
      " 'source': 802,\n",
      " 'transformer': 803}\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/Kossyo/Desktop/Уни/Power System computation and simulation/big_network/input/input_network_data.json\") as fp:\n",
    "    data = fp.read()\n",
    "\n",
    "input_data = json_deserialize(data)\n",
    "\n",
    "with open(\"C:/Users/Kossyo/Desktop/Уни/Power System computation and simulation/big_network/input/meta_data.json\") as fp:\n",
    "    meta = fp.read()\n",
    "\n",
    "meta_data = json.loads(meta)\n",
    "pprint.pprint(meta_data)\n",
    "\n",
    "active_power_profile = pd.read_parquet(\"C:/Users/Kossyo/Desktop/Уни/Power System computation and simulation/big_network/input/active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"C:/Users/Kossyo/Desktop/Уни/Power System computation and simulation/big_network/input/active_power_profile.parquet\")\n",
    "ev_active_power_profile = pd.read_parquet(\"C:/Users/Kossyo/Desktop/Уни/Power System computation and simulation/big_network/input/active_power_profile.parquet\")\n",
    "\n",
    "dtype = {\n",
    "    \"names\": [\n",
    "        \"id\",\n",
    "        \"from_node\",\n",
    "        \"to_node\",\n",
    "        \"from_status\",\n",
    "        \"to_status\",\n",
    "        \"r1\",\n",
    "        \"x1\",\n",
    "        \"c1\",\n",
    "        \"tan1\",\n",
    "        \"r0\",\n",
    "        \"x0\",\n",
    "        \"c0\",\n",
    "        \"tan0\",\n",
    "        \"i_n\",\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(\n",
    "    input_data[ComponentType.line], columns=dtype[\"names\"]\n",
    ")  # get the data for the lines of the grid as a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c7975",
   "metadata": {},
   "source": [
    "# **Input data validity check**\n",
    "\n",
    "Check the following validity criteria for the input data. Raise or passthrough relevant errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e65aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreThanOneTransformerOrSource(Exception):\n",
    "    \"Raised when there is more than one transformer or source in meta_data.json\"\n",
    "\n",
    "\n",
    "class InvalidLVIds(Exception):\n",
    "    \"Raised when LV Feeder IDs are not valid line IDs.\"\n",
    "\n",
    "\n",
    "class NonMatchingTransformerLineNodes(Exception):\n",
    "    \"Raised when the lines in the LV Feeder IDs do not have the from_node the same as the to_node of the transformer.\"\n",
    "\n",
    "\n",
    "class NonMatchingTimestamps(Exception):\n",
    "    \"Raised when the timestamps are not matching between the active load profile, reactive load profile, and EV charging profile.\"\n",
    "\n",
    "\n",
    "class InvalidProfileIds(Exception):\n",
    "    \"Raised when the IDs in active load profile and reactive load profile are not matching.\"\n",
    "\n",
    "\n",
    "class InvalidSymloadIds(Exception):\n",
    "    \"Raised when the IDs in active load profile and reactive load profile are not matching the symload IDs.\"\n",
    "\n",
    "\n",
    "class InvalidNumberOfEVProfiles(Exception):\n",
    "    \"raised when the number of EV charging profile is at least the same as the number of sym_load.\"\n",
    "\n",
    "\n",
    "class InvalidLineIds(Exception):\n",
    "    \"Raised when the given Line ID to disconnect is not a valid\"\n",
    "\n",
    "\n",
    "class NonConnnected(Exception):\n",
    "    \"Raised when the given Line ID is not connected at both sides in the base case\"\n",
    "\n",
    "\n",
    "class InvalidCriteria(Exception):\n",
    "    \"Raised when the criteria for optimal tap position is not valid. Use 'Voltage_deviation' or 'Total_loss'.\"\n",
    "\n",
    "\n",
    "def check_source_transformer(meta_data):\n",
    "    if (type(meta_data[\"source\"]) is not int) or (type(meta_data[\"transformer\"]) is not int):\n",
    "        raise MoreThanOneTransformerOrSource(\"LV grid contains more than one source or transformer\")\n",
    "\n",
    "\n",
    "def check_valid_LV_ids(LV_ids, Line_ids):\n",
    "    if not all(item in Line_ids for item in LV_ids):\n",
    "        raise InvalidLVIds(\"LV feeders contain invalid ids\")\n",
    "\n",
    "\n",
    "def check_line_transformer_nodes(lines_from_nodes, transformer_to_node):\n",
    "    if not all(element == transformer_to_node for element in lines_from_nodes):\n",
    "        raise NonMatchingTransformerLineNodes(\n",
    "            \"The lines in the LV Feeder IDs do not have the from_node the same as the to_node of the transformer\"\n",
    "        )\n",
    "\n",
    "\n",
    "def check_timestamps(active_timestamp, reactive_timestamp, ev_timestamp):\n",
    "    if not (active_timestamp.equals(reactive_timestamp) and active_timestamp.equals(ev_timestamp)):\n",
    "        raise NonMatchingTimestamps(\"Timestamps between the active, reactive and ev profiles do not match\")\n",
    "\n",
    "\n",
    "def check_profile_ids(active_ids, reactive_ids):\n",
    "    if not active_ids.equals(reactive_ids):\n",
    "        raise InvalidProfileIds(\"The active and reactive load profile IDs are not matching\")\n",
    "\n",
    "\n",
    "def check_symload_ids(active_ids, reactive_ids, symload_ids):\n",
    "    if not (all(item in symload_ids for item in active_ids) and (all(item in symload_ids for item in reactive_ids))):\n",
    "        raise InvalidSymloadIds(\"The active and reactive load profile IDs are not matching the sym_load IDs\")\n",
    "\n",
    "\n",
    "def check_number_of_ev_profiles(ev_profiles, symload_profiles):\n",
    "    if len(ev_profiles) > len(symload_profiles):\n",
    "        raise InvalidNumberOfEVProfiles(\"The number of EV charging profile is larger than the number of sym_loads\")\n",
    "\n",
    "\n",
    "def check_valid_line_ids(id, Line_ids):\n",
    "    if id not in Line_ids:\n",
    "        raise InvalidLineIds(\"Invalid Line ID\")\n",
    "\n",
    "\n",
    "def check_line_id_connected(fr, to):\n",
    "    if not (fr.item() == 1 and to.item() == 1):\n",
    "        raise NonConnnected(\"Line ID not connected at both sides in the base case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1439a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data_validity_check(input_data, meta_data):\n",
    "\n",
    "    assert_valid_input_data(\n",
    "        input_data=input_data, calculation_type=CalculationType.power_flow\n",
    "    )  # check if input data is valid\n",
    "    check_source_transformer(meta_data)  # check if LV grid has exactly one transformer, and one source.\n",
    "\n",
    "    check_valid_LV_ids(\n",
    "        meta_data[\"lv_feeders\"], input_data[ComponentType.line][\"id\"]\n",
    "    )  # check if All IDs in the LV Feeder IDs are valid line IDs\n",
    "    check_line_transformer_nodes(\n",
    "        df[df[\"id\"].isin(meta_data[\"lv_feeders\"])][\"from_node\"].tolist(),\n",
    "        input_data[ComponentType.transformer][\"to_node\"],\n",
    "    )  # check if all the lines in the LV Feeder IDs have the from_node the same as the to_node of the transformer\n",
    "\n",
    "    transformer_tuple = list(\n",
    "        zip(\n",
    "            input_data[ComponentType.transformer][\"from_node\"].tolist(),\n",
    "            input_data[ComponentType.transformer][\"to_node\"].tolist(),\n",
    "        )\n",
    "    )  # transformer also connects two nodes\n",
    "    line_nodes_id_pairs = (\n",
    "        list(\n",
    "            zip(\n",
    "                input_data[ComponentType.line][\"from_node\"].tolist(), input_data[ComponentType.line][\"to_node\"].tolist()\n",
    "            )\n",
    "        )\n",
    "        + transformer_tuple\n",
    "    )  # add nodes connected by transformer to list of lines connecting nodes\n",
    "    status_list = list(input_data[ComponentType.line][\"to_status\"].tolist()) + list(\n",
    "        input_data[ComponentType.transformer][\"to_status\"].tolist()\n",
    "    )  # add transformer connection status to list of lines' statuses\n",
    "\n",
    "    check_connect(\n",
    "        input_data[ComponentType.node][\"id\"], status_list, line_nodes_id_pairs\n",
    "    )  # check if the grid is fully connected in the initial state\n",
    "    check_cycle(status_list, line_nodes_id_pairs)  # check if the grid has no cycles in the initial state\n",
    "\n",
    "    check_timestamps(\n",
    "        active_power_profile.index, reactive_power_profile.index, ev_active_power_profile.index\n",
    "    )  # checks if timestamps are matching\n",
    "    check_profile_ids(\n",
    "        active_power_profile.columns, reactive_power_profile.columns\n",
    "    )  # checks if number of active and reactive profiles are matching\n",
    "    check_symload_ids(\n",
    "        active_power_profile.columns, reactive_power_profile.columns, input_data[ComponentType.sym_load][\"id\"]\n",
    "    )  # checks if IDs are matching\n",
    "    check_number_of_ev_profiles(\n",
    "        ev_active_power_profile.columns, input_data[ComponentType.sym_load][\"id\"]\n",
    "    )  # checks if number of EV profiles does not exceed number of sym_loads\n",
    "    print(\"Input data is valid!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4e730",
   "metadata": {},
   "source": [
    "Validity check tested on big network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "534701f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data is valid!\n"
     ]
    }
   ],
   "source": [
    "input_data_validity_check(input_data, meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8558079",
   "metadata": {},
   "source": [
    "# **EV penetration**\n",
    "\n",
    "Given a (user-provided) input of electrical vehicle (EV) penetration level, i.e. the percentage of houses which has EV charged at home, randomly add EV charging profiles to the houses according to the following creteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8841",
   "metadata": {},
   "source": [
    "# **Optimal tap position**\n",
    "\n",
    "In this functionality, the user would like to optimize the tap position of the transformer in the LV grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf22e2",
   "metadata": {},
   "source": [
    "# **N-1 calculation**\n",
    "\n",
    "In this functionality, the user would like to know alternative grid topology when a given line is out of service. The user will provide the Line ID which is going to be out of service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de2d0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_line_ids(id, Line_ids):\n",
    "    if id not in Line_ids:\n",
    "        raise InvalidLineIds(\"Invalid Line ID\")\n",
    "\n",
    "\n",
    "def check_line_id_connected(fr, to):\n",
    "    if not (fr.item() == 1 and to.item() == 1):\n",
    "        raise NonConnnected(\"Line ID not connected at both sides in the base case\")\n",
    "\n",
    "\n",
    "def find_alternative_lines(\n",
    "    vertex_ids, edge_ids, edge_vertex_id_pairs, edge_enabled, source_vertex_id, id_to_disconnect\n",
    "):\n",
    "    test = GraphProcessor(\n",
    "        vertex_ids, edge_ids, edge_vertex_id_pairs, edge_enabled, source_vertex_id\n",
    "    )  # create a graph from the provided data about nodes and lines\n",
    "    return test.find_alternative_edges(\n",
    "        id_to_disconnect\n",
    "    )  # find the alternative edges to make the graph fully connected, when the line is disconnected\n",
    "\n",
    "\n",
    "def power_flow_calc(active_power_profile, alt_lines_list, line_id_list):\n",
    "\n",
    "    load_profile_active = initialize_array(DatasetType.update, ComponentType.sym_load, active_power_profile.shape)\n",
    "    load_profile_active[\"id\"] = active_power_profile.columns.to_numpy()\n",
    "    load_profile_active[\"p_specified\"] = active_power_profile.to_numpy()\n",
    "    load_profile_active[\"q_specified\"] = 0.0\n",
    "    update_data = {ComponentType.sym_load: load_profile_active}\n",
    "\n",
    "    input_data[ComponentType.line][\"from_status\"][\n",
    "        line_id_list.index(id_to_disconnect)\n",
    "    ] = 0  # disconnect the line that the user wants to disconnect\n",
    "    input_data[ComponentType.line][\"to_status\"][\n",
    "        line_id_list.index(id_to_disconnect)\n",
    "    ] = 0  # disconnect the line that the user wants to disconnect\n",
    "\n",
    "    max_loading_alt = np.zeros(len(alt_lines_list))  # initialize max_loading column values\n",
    "    max_line_alt = np.zeros(len(alt_lines_list))  # initialize max_line_alt column values\n",
    "    max_loading_timestamp_alt = np.zeros(\n",
    "        len(alt_lines_list), dtype=object\n",
    "    )  # initialize max_loading_timestamp column values\n",
    "    for k in range(len(alt_lines_list)):\n",
    "        input_data[ComponentType.line][\"from_status\"][k] = 1\n",
    "        input_data[ComponentType.line][\"to_status\"][k] = 1  # connect the kth alternative line\n",
    "        model = PowerGridModel(input_data=input_data)\n",
    "        result = model.calculate_power_flow(\n",
    "            update_data=update_data, calculation_method=CalculationMethod.newton_raphson\n",
    "        )  # perform the power flow analysis when the kth line is connected\n",
    "        # print(alt_lines_list[k])\n",
    "        # print(result)\n",
    "        ids = np.unique(result[ComponentType.line][\"id\"])\n",
    "        max_loading = np.zeros(len(ids))\n",
    "        max_loading_timestamp = np.zeros(len(ids), dtype=object)\n",
    "        temp_max = -99999999\n",
    "        for i in range(len(ids)):\n",
    "            max_loading[i] = result[ComponentType.line][\"loading\"][:, i].max()\n",
    "            for j in range(len(active_power_profile.index)):\n",
    "                if max_loading[i] == result[ComponentType.line][\"loading\"][j, i]:\n",
    "                    max_loading_timestamp[i] = active_power_profile.index[j]\n",
    "                    if max_loading[i] > temp_max:\n",
    "                        temp_max = max_loading[i]\n",
    "                        max_loading_alt[k] = max_loading[i]\n",
    "                        max_line_alt[k] = result[ComponentType.line][\"id\"][j, i]\n",
    "                        max_loading_timestamp_alt[k] = active_power_profile.index[j]\n",
    "                        # print(active_power_profile.index[j])\n",
    "        input_data[ComponentType.line][\"from_status\"][k] = 0\n",
    "        input_data[ComponentType.line][\"to_status\"][k] = 0  # disconnect kth line\n",
    "\n",
    "    input_data[ComponentType.line][\"from_status\"][\n",
    "        line_id_list.index(id_to_disconnect)\n",
    "    ] = 1  # reconnect the line that the user wants to disconnect\n",
    "    input_data[ComponentType.line][\"to_status\"][\n",
    "        line_id_list.index(id_to_disconnect)\n",
    "    ] = 1  # reconnect the line that the user wants to disconnect\n",
    "\n",
    "    output_data = pd.DataFrame()  # generate specified table from assignment 3\n",
    "    output_data[\"Alternative line ID\"] = alt_lines_list\n",
    "    output_data[\"Max_loading\"] = max_loading_alt\n",
    "    output_data[\"Max_line_id\"] = max_line_alt\n",
    "    output_data[\"Max_timestamp\"] = max_loading_timestamp_alt\n",
    "    display(output_data)\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8243f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_minus_one_calculation(id_to_disconnect):\n",
    "\n",
    "    check_valid_line_ids(id_to_disconnect, input_data[ComponentType.line][\"id\"])  # check if ID is valid\n",
    "    check_line_id_connected(\n",
    "        df[df[\"id\"] == id_to_disconnect][\"from_status\"], df[df[\"id\"] == id_to_disconnect][\"to_status\"]\n",
    "    )  # check if line with selected ID is connected\n",
    "\n",
    "    transformer_tuple = list(\n",
    "        zip(\n",
    "            input_data[ComponentType.transformer][\"from_node\"].tolist(),\n",
    "            input_data[ComponentType.transformer][\"to_node\"].tolist(),\n",
    "        )\n",
    "    )  # transformer also connects two nodes\n",
    "    line_nodes_id_pairs = (\n",
    "        list(\n",
    "            zip(\n",
    "                input_data[ComponentType.line][\"from_node\"].tolist(), input_data[ComponentType.line][\"to_node\"].tolist()\n",
    "            )\n",
    "        )\n",
    "        + transformer_tuple\n",
    "    )  # add nodes connected by transformer to list of lines connecting nodes\n",
    "    status_list = list(df[\"to_status\"].tolist()) + list(\n",
    "        input_data[ComponentType.transformer][\"to_status\"].tolist()\n",
    "    )  # add transformer connection status to list of lines' statuses\n",
    "    line_id_list = df[\"id\"].tolist()\n",
    "    new_id = (df[\"id\"].iloc[-1] + 1).tolist()\n",
    "    line_id_list.append(new_id)  # add another line id to mimic the transformer connection\n",
    "    alt_lines_list = find_alternative_lines(\n",
    "        input_data[ComponentType.node][\"id\"].tolist(),\n",
    "        line_id_list,\n",
    "        line_nodes_id_pairs,\n",
    "        status_list,\n",
    "        meta_data[\"mv_source_node\"],\n",
    "        id_to_disconnect,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"To make the grid fully connected, the following lines need to be connected: {alt_lines_list}\"\n",
    "    )  # find alternative currently disconnected lines to make the grid fully connected\n",
    "\n",
    "    power_flow_calc(active_power_profile, alt_lines_list, line_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7c41d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make the grid fully connected, the following lines need to be connected: [2010]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alternative line ID</th>\n",
       "      <th>Max_loading</th>\n",
       "      <th>Max_line_id</th>\n",
       "      <th>Max_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.073859</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>2025-11-05 06:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alternative line ID  Max_loading  Max_line_id       Max_timestamp\n",
       "0                 2010     0.073859       1906.0 2025-11-05 06:45:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id_to_disconnect = 2002 #returns [2010] list and a table of 1 row\n",
    "N_minus_one_calculation(id_to_disconnect) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
